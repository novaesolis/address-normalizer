# -*- coding: utf-8 -*-
"""txt_sber_06_rf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ai2wWW8Bcj9IIBQkm2QDk1mR3ydKlgCS
"""

# подгружаем необходимые библиотеки и фиксируем random state

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import re
import scipy
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

RS=42

#подключаем гугл диск на котором данные
from google.colab import drive
drive.mount ('/content/gdrive', force_remount = True)

#загружаем данные в датафреймы
bad_df=pd.read_csv('../content/gdrive/My Drive/dataset_sber_dj/bad.csv',sep=';')
bad_df.head(1_000_000)

#загружаем данные в датафреймы
good_df=pd.read_csv('../content/gdrive/My Drive/dataset_sber_dj/good_half2.csv',sep=';',index_col='num')
good_df.head(1_000_000)

good_df.rename(columns={'type':'detection_level',	'country':'country',	'town':'region',	'field8':'gorod',\
                        'field9':'mesto',	'fiel10':'region_type',	'field11':'rayon',	\
                        'field12':'type_street',	'field13':'street',	'field14':'dom'	,'field15':'kv',	'field16':'ofice'},\
               inplace=True)
good_df.head()

good_df.describe()

#заполняем пустые ячейки
good_df.fillna(value='0',inplace=True)
good_df.head(1_000_000)

TOKEN_RE = re.compile(r'[\w\d]+')  #regular expression to start with

def tokenize_text_simple_regex(txt, min_token_size=2):
    """ This func tokenize text with TOKEN_RE applied ealier """
    txt = txt.lower()
    all_tokens = TOKEN_RE.findall(txt)
    return [token for token in all_tokens if len(token) >= min_token_size]

X=good_df.original
X.head()

y=good_df[['detection_level','country','region','gorod','mesto','region_type','rayon','type_street']]
y.head()

#Количество меток
y.detection_level.nunique()

y.country.nunique()

y.gorod.nunique()

y.type_street.nunique()

X_train, y_train, X_test, y_test=train_test_split(X, y, test_size=0.2)

sklearn_pipeline = Pipeline((('vect', TfidfVectorizer(tokenizer=tokenize_text_simple_regex,
                                                      max_df=0.7,
                                                      min_df=6)),
                             ('cls', RandomForestClassifier(verbose=True,random_state=RS))))

sklearn_pipeline.fit(X[:2000], y[:2000]);

sklearn_train_pred = sklearn_pipeline.predict_proba(X[:1000])
print(sklearn_train_pred[:10])

type_classes= sklearn_pipeline.predict(X[:10])
print(type_classes[:10])

prediction_out= sklearn_pipeline.predict(bad_df.address)
print(prediction_out[:10])

prediction_out.shape

bad_df.shape

out_df=pd.concat([bad_df,pd.DataFrame(prediction_out)],axis=1)
out_df.head()

out_df.tail()

out_df.to_csv('submission.csv',index=False)

from google.colab import files
files.download('submission.csv')

#сделаем вторую модель для оставшихся фичей (ТИП УЛИЦЫ, УЛИЦА, ДОМ, СТРОЕНИЕ, КВ). Т.К. все сделать в одной модели не хватает памяти
y2=good_df[['street','dom','kv']]
y2.head()

y2.street.nunique()

sklearn_pipeline2 = Pipeline((('vect', TfidfVectorizer(tokenizer=tokenize_text_simple_regex,
                                                      max_df=0.7,
                                                      min_df=6)),
                             ('cls', RandomForestClassifier(verbose=True,random_state=RS))))

sklearn_pipeline2.fit(X[:5000], y[:5000]);

sklearn_train_pred2 = sklearn_pipeline2.predict_proba(X[:1000])
print(sklearn_train_pred2[:10])

type_classes2= sklearn_pipeline2.predict(X[:10])
print(type_classes2[:10])







# save the model to disk
filename = 'model_dj05_1.sav'
pickle.dump(sklearn_pipeline, open(filename, 'wb'))

# some time later...

# load the model from disk
#loaded_model = pickle.load(open(filename, 'rb'))
#result = loaded_model.score(X_test, Y_test)
#print(result)

!ls



from google.colab import files
files.download('model_dj05_1.sav')

# save the model to disk
filename = 'model_dj05_2.sav'
pickle.dump(sklearn_pipeline2, open(filename, 'wb'))

from google.colab import files
files.download('model_dj05_2.sav')